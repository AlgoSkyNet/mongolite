[
["index.html", "Mongolite User Manual Chapter 1 Getting Started 1.1 Requirements (Linux / Mac) 1.2 Install mongolite in R 1.3 Run local mongod 1.4 Testing with SSL", " Mongolite User Manual Version 2018-08-02 Chapter 1 Getting Started This book provides a high level introduction to using MongoDB with the mongolite client in R. 1.1 Requirements (Linux / Mac) Installation from source on Linux requires openssl and Cyrus SASL (not GNU sasl). On Debian or Ubuntu use libssl-dev and libsasl2-dev: sudo apt-get install -y libssl-dev libsasl2-dev On Fedora, CentOS or RHEL use openssl-devel and cyrus-sasl-devel: sudo yum install openssl-devel cyrus-sasl-devel On OS-X sasl is included with the system so only openssl is needed. brew install openssl On Windows all dependencies are statically linked with mongolite; no separate installation is required. Elsewhere, mongolite will automatically find the system libraries when installed in default locations. 1.2 Install mongolite in R Binary packages of mongolite for OS-X or Windows can be installed directly from CRAN: install.packages(&quot;mongolite&quot;) Alternatively you can install the development version, which contains the latest features and bugs. This required compiling from source: # installs development version of &#39;mongolite&#39; devtools::install_github(&quot;jeroen/mongolite&quot;) Note that Windows users need to install the Rtools toolchain in order to compile from source. This is not needed for the CRAN version above. 1.3 Run local mongod Please refer to the official MongoDB install manual for instructions how to setup a local MongoDB server. To get started on MacOS, simply use: brew install mongodb The Homebrew package does not install any system services. To run the daemon in a console: mongod Use this for running examples as the mongolite package defaults to url = &quot;mongodb://localhost&quot;. 1.4 Testing with SSL To run a local mongod with SSL support you need a SSL key and certificate. See the Mongo Configure SSL manual page. A generate a self signed cert for testing purposes: cd /etc/ssl/ openssl req -newkey rsa:2048 -new -x509 -days 365 -nodes -out mongodb-cert.crt -keyout mongodb-cert.key cat mongodb-cert.key mongodb-cert.crt &gt; mongodb.pem And then start the daemon with: mongod --sslMode requireSSL --sslPEMKeyFile /etc/ssl/mongodb.pem Because this certificate has not been signed with a CA, you need to set weak_cert_validation in the client to connect: m &lt;- mongo(url = &quot;mongodb://localhost/?ssl=true&quot;, options = ssl_options(weak_cert_validation = T)) Obviously in production you need to get your cert signed by a CA instead. "],
["connecting-to-mongodb.html", "Chapter 2 Connecting to MongoDB 2.1 Mongo URI Format 2.2 Authentication 2.3 SSH Tunnel 2.4 SSL options 2.5 Replica Options 2.6 Global options", " Chapter 2 Connecting to MongoDB 2.1 Mongo URI Format The mongo() function initiates a connection object to a MongoDB server. For example: library(mongolite) m &lt;- mongo(&quot;mtcars&quot;, url = &quot;mongodb://readwrite:test@ds043942.mongolab.com:43942/jeroen_test&quot;) To get an overview of available methods, simply print the object to the terminal. print(m) #&gt; &lt;Mongo collection&gt; &#39;mtcars&#39; #&gt; $aggregate(pipeline = &quot;{}&quot;, options = &quot;{\\&quot;allowDiskUse\\&quot;:true}&quot;, handler = NULL, pagesize = 1000) #&gt; $count(query = &quot;{}&quot;) #&gt; $distinct(key, query = &quot;{}&quot;) #&gt; $drop() #&gt; $export(con = stdout(), bson = FALSE) #&gt; $find(query = &quot;{}&quot;, fields = &quot;{\\&quot;_id\\&quot;:0}&quot;, sort = &quot;{}&quot;, skip = 0, limit = 0, handler = NULL, pagesize = 1000) #&gt; $import(con, bson = FALSE) #&gt; $index(add = NULL, remove = NULL) #&gt; $info() #&gt; $insert(data, pagesize = 1000, stop_on_error = TRUE, ...) #&gt; $iterate(query = &quot;{}&quot;, fields = &quot;{\\&quot;_id\\&quot;:0}&quot;, sort = &quot;{}&quot;, skip = 0, limit = 0) #&gt; $mapreduce(map, reduce, query = &quot;{}&quot;, sort = &quot;{}&quot;, limit = 0, out = NULL, scope = NULL) #&gt; $remove(query, just_one = FALSE) #&gt; $rename(name, db = NULL) #&gt; $replace(query, update = &quot;{}&quot;, upsert = FALSE) #&gt; $run(command = &quot;{\\&quot;ping\\&quot;: 1}&quot;) #&gt; $update(query, update = &quot;{\\&quot;$set\\&quot;:{}}&quot;, filters = NULL, upsert = FALSE, multiple = FALSE) The R manual page for the mongo() function gives some brief descriptions as well. ?mongo The manual page tells us that mongo() supports the following arguments: collection: name of the collection to connect to. Defaults to &quot;test&quot;. db: name of the database to connect to. Defaults to &quot;test&quot;. url: address of the MongoDB server in standard URI Format. verbose: if TRUE, emits some extra output options: additional connection options such as SSL keys/certs. The url parameter contains a special URI format which defines the server address and additional connection options. mongodb://[username:password@]host1[:port1][,host2[:port2],...[/[database][?options]] The Mongo Connection String Manual gives an overview of the connection string syntax and options. Below the most important options for using mongolite. 2.1.1 DNS Seedlist Connection Format New in mongolite 1.3 is support for seedlist URLs with the mongodb+srv:// prefix. This indicates that before connecting, the client should lookup the actual host addresses and parameters from the DNS SRV or TXT record. con &lt;- mongo(&quot;mtcars&quot;, url = &quot;mongodb+srv://readwrite:test@cluster0-84vdt.mongodb.net/test&quot;) con$insert(mtcars) #&gt; List of 5 #&gt; $ nInserted : num 32 #&gt; $ nMatched : num 0 #&gt; $ nRemoved : num 0 #&gt; $ nUpserted : num 0 #&gt; $ writeErrors: list() con$drop() The DNS seedlist allows for using a short and fixed URL for clusters consisting of multiple or dynamic servers and parameters. 2.2 Authentication MongoDB supports several authentication modes. 2.2.1 LDAP USER = &quot;drivers-team&quot; PASS = &quot;mongor0x$xgen&quot; HOST = &quot;ldaptest.10gen.cc&quot; # Using plain-text URI = sprintf(&quot;mongodb://%s:%s@%s/ldap?authMechanism=PLAIN&quot;, USER, PASS, HOST) m &lt;- mongo(url = URI) m$find() However it is recommended to use SSL instead of plain text when authenticating with a username/password: # Or over SSL m &lt;- mongo(url = paste0(URI, &quot;&amp;ssl=true&quot;), options = ssl_options(ca = &quot;.auth/ca.crt&quot;, allow_invalid_hostname = TRUE)) m$find() 2.2.2 X509 Let’s check if our server supports SSL: certs &lt;- openssl::download_ssl_cert(&#39;ldaptest.10gen.cc&#39;, 27017) print(certs) str(as.list(certs[[1]])) To use X509 authentication the Mongo URI needs ssl=true&amp;authMechanism=MONGODB-X509: # Using X509 SSL auth HOST &lt;- &quot;ldaptest.10gen.cc&quot; USER &lt;- &quot;CN=client,OU=kerneluser,O=10Gen,L=New York City,ST=New York,C=US&quot; URI &lt;- sprintf(&quot;mongodb://%s@%s/x509?ssl=true&amp;authMechanism=MONGODB-X509&quot;, USER, HOST) OPTS &lt;- ssl_options(cert = &quot;.auth/client.pem&quot;, key = &quot;.auth/key.pem&quot;, ca = &quot;.auth/ca.crt&quot;, allow_invalid_hostname = TRUE) m &lt;- mongo(url = URI, options = OPTS) m$find() 2.2.3 Kerberos Note: Windows uses SSPI for Kerberos authentication. This section does not apply. Kerberos authentication on Linux requires installation of a Kerberos client. On OS-X Kerberos is already installed by default. On Ubuntu/Debian we need: sudo apt-get install krb5-user libsasl2-modules-gssapi-mit Next, create or edit /etc/krbs5.conf and add our server under [realms] for example: [realms] LDAPTEST.10GEN.CC = { kdc = ldaptest.10gen.cc admin_server = ldaptest.10gen.cc } In a terminal run the following (only have to do this once) kinit drivers@LDAPTEST.10GEN.CC klist We should now be able to connect in R: HOST &lt;- &quot;ldaptest.10gen.cc&quot; USER &lt;- &quot;drivers%40LDAPTEST.10GEN.CC&quot; URI &lt;- sprintf(&quot;mongodb://%s@%s/kerberos?authMechanism=GSSAPI&quot;, USER, HOST) m &lt;- mongo(url = URI) m$find() 2.3 SSH Tunnel To connect to MongoDB via an SSH tunnel, you need to setup the tunnel separately with an SSH client. For example the mongolite manual contains this example: con &lt;- mongo(&quot;mtcars&quot;, url = &quot;mongodb://readwrite:test@ds043942.mongolab.com:43942/jeroen_test&quot;) Assume we want to tunnel through dev.opencpu.org which runs an SSH server on the standard port 22 with username jeroen. To initiate a tunnel from localhost:9999 to ds043942.mongolab.com:43942 via the ssh server dev.opencpu.org:22, open a terminal and run: ssh -L 9999:ds043942.mongolab.com:43942 jeroen@dev.opencpu.org -vN -p22 Some relevant ssh flags: -v (optional) show verbose status output -f run the tunnel server in the background. Use pkill ssh to kill. -p22 connect to ssh server on port 22 (default) -i/some/path/id_rsa authenticate with ssh using a private key Check man ssh for more ssh options It is also possible to run this command directly from R: system(&quot;ssh -L 9999:ds043942.mongolab.com:43942 jeroen@dev.opencpu.org -fN -p22&quot;) Sys.sleep(1) Once tunnel has been established, we can connect to our our ssh client which will tunnel traffic to our MongoDB server. In our example we run the ssh client on our localhost port 9999: con &lt;- mongo(&quot;mtcars&quot;, url = &quot;mongodb://readwrite:test@localhost:9999/jeroen_test&quot;) con$insert(mtcars) #&gt; List of 5 #&gt; $ nInserted : num 32 #&gt; $ nMatched : num 0 #&gt; $ nRemoved : num 0 #&gt; $ nUpserted : num 0 #&gt; $ writeErrors: list() #&gt; used (Mb) gc trigger (Mb) limit (Mb) max used (Mb) #&gt; Ncells 577870 30.9 1155822 61.8 NA 1104972 59.1 #&gt; Vcells 1183163 9.1 8388608 64.0 16384 2069573 15.8 If you want to setup a tunnel client on Windows and you do not have the ssh program, you can an SSH client like putty to setup the tunnel. See this example. 2.4 SSL options For security reasons, SSL options can not be configured in the URI but have to be set manually via the options parameter. The ssl_options function shows the default values: ssl_options() #&gt; List of 6 #&gt; $ pem_file : NULL #&gt; $ ca_file : NULL #&gt; $ ca_dir : NULL #&gt; $ crl_file : NULL #&gt; $ allow_invalid_hostname: logi FALSE #&gt; $ weak_cert_validation : logi FALSE You can use this function to specify connection SSL options: m &lt;- mongo(url = &quot;mongodb://localhost?ssl=true&quot;, options = ssl_options(cert = &quot;~/client.crt&quot;, key = &quot;~/id_rsa.pem&quot;)) The MongoDB SSL client manual has more detailed descriptions on the various options. 2.5 Replica Options The URI accepts a few special keys when connecting to a replicaset. The connection-string manual is the canonical source for all parameters. Most users should stick with the defaults here, only specify these if you know what you are doing. 2.5.1 Read Preference The Read Preference parameter specifies if the client should connect to the primary node (default) or a secondary node in the replica set. m &lt;- mongo(url = &quot;mongodb://host.example.com/?readPreference=secondary&quot;) 2.5.2 Write Concern The Write Concern parameter is used to specify the level of acknowledgement that the write operation has propagated to a number of server nodes. The url string parameter is the letter w. m &lt;- mongo(url = &quot;mongodb://host.example.com/?w=2&quot;) Note that specifying this parameter to 2 on a server that is not a replicaset will result in an error when trying to write: m &lt;- mongo(url = &quot;mongodb://localhost/?w=2&quot;) m$insert(&#39;{&quot;foo&quot; : &quot;bar&quot;}&#39;) #&gt; Error: cannot use &#39;w&#39; &gt; 1 when a host is not replicated 2.5.3 Read Concern Finally, Read Concern allows clients to choose a level of isolation for their reads from replica sets. The default value local returns the instance’s most recent data, but provides no guarantee that the data has been written to a majority of the replica set members (i.e. may be rolled back). On the other hand, if we specify majority the server will only return data that has been propagated to the majority of nodes. m &lt;- mongo(url = &quot;mongodb://localhost/?readConcernLevel=majority&quot;) m$insert(&#39;{&quot;foo&quot;: 123}&#39;) #&gt; List of 6 #&gt; $ nInserted : int 1 #&gt; $ nMatched : int 0 #&gt; $ nModified : int 0 #&gt; $ nRemoved : int 0 #&gt; $ nUpserted : int 0 #&gt; $ writeErrors: list() m$insert(&#39;{&quot;foo&quot;: 456}&#39;) #&gt; List of 6 #&gt; $ nInserted : int 1 #&gt; $ nMatched : int 0 #&gt; $ nModified : int 0 #&gt; $ nRemoved : int 0 #&gt; $ nUpserted : int 0 #&gt; $ writeErrors: list() In the case of our local single-node server this is never the case. Therefore we see that the server does not return any data that meets the majority level. m$count() #&gt; [1] 2 m$find() #&gt; foo #&gt; 1 123 #&gt; 2 456 The data is definitely there though, it just doesn’t meet the majority criterium. If we create a new connection with level local we do get to see our data: m2 &lt;- mongo(url = &quot;mongodb://localhost/?readConcernLevel=local&quot;) m2$count() #&gt; [1] 2 m2$find() #&gt; foo #&gt; 1 123 #&gt; 2 456 2.6 Global options Finally the mongo_options method allows for setting global client options that span across connections. Currently two options are supported: log_level set the mongo log level, e.g. for printing debugging information. bigint_as_char set to TRUE to parse int64 numbers as strings rather than doubles (R does not support large integers natively) The default values are: mongo_options() #&gt; $log_level #&gt; [1] &quot;INFO&quot; #&gt; #&gt; $bigint_as_char #&gt; [1] FALSE #&gt; #&gt; $date_as_char #&gt; [1] FALSE See the manual page for ?mongo_options for more details. "],
["query-data.html", "Chapter 3 Query Data 3.1 Query syntax 3.2 Filter fields 3.3 Sort and limit 3.4 Indexing 3.5 Iterating 3.6 Select by date 3.7 Select by ID", " Chapter 3 Query Data This chapter will cover basic techniques for reading data from MongoDB. To exemplify this chapter we start by creating a new collection diamonds and insert an example dataset from the ggplot2 package. # create collection with example data dmd &lt;- mongo(&quot;diamonds&quot;) dmd$insert(ggplot2::diamonds) #&gt; List of 5 #&gt; $ nInserted : num 53940 #&gt; $ nMatched : num 0 #&gt; $ nRemoved : num 0 #&gt; $ nUpserted : num 0 #&gt; $ writeErrors: list() The next chapter explains inserting data in more detail. For now let’s verify all our data was inserted: dmd$count() == nrow(ggplot2::diamonds) #&gt; [1] FALSE Seems good! 3.1 Query syntax MongoDB uses JSON based syntax to query documents. The empty query {} means: select all data. The same query parameter is used for multiple operations such as find(), iterate(), count(), remove() and update(). We need to specify the JSON query as a string in R. # Get all records dmd$count(&#39;{}&#39;) #&gt; [1] 107880 # Read all the data back into R alldata &lt;- dmd$find(&#39;{}&#39;) print(alldata) #&gt; carat cut color clarity depth table price x y z #&gt; 1 0.23 Ideal E SI2 61.5 55.0 326 3.95 3.98 2.43 #&gt; 2 0.21 Premium E SI1 59.8 61.0 326 3.89 3.84 2.31 #&gt; 3 0.23 Good E VS1 56.9 65.0 327 4.05 4.07 2.31 #&gt; 4 0.29 Premium I VS2 62.4 58.0 334 4.20 4.23 2.63 #&gt; 5 0.31 Good J SI2 63.3 58.0 335 4.34 4.35 2.75 #&gt; 6 0.24 Very Good J VVS2 62.8 57.0 336 3.94 3.96 2.48 #&gt; 7 0.24 Very Good I VVS1 62.3 57.0 336 3.95 3.98 2.47 #&gt; 8 0.26 Very Good H SI1 61.9 55.0 337 4.07 4.11 2.53 #&gt; 9 0.22 Fair E VS2 65.1 61.0 337 3.87 3.78 2.49 #&gt; 10 0.23 Very Good H VS1 59.4 61.0 338 4.00 4.05 2.39 #&gt; [ reached getOption(&quot;max.print&quot;) -- omitted 107870 rows ] To query all rows where cut == &quot;Premium&quot; AND price &lt; 1000 you would run: premium_diamonds &lt;- dmd$find(&#39;{&quot;cut&quot; : &quot;Premium&quot;, &quot;price&quot; : { &quot;$lt&quot; : 1000 } }&#39;) print(premium_diamonds) #&gt; carat cut color clarity depth table price x y z #&gt; 1 0.21 Premium E SI1 59.8 61.0 326 3.89 3.84 2.31 #&gt; 2 0.29 Premium I VS2 62.4 58.0 334 4.20 4.23 2.63 #&gt; 3 0.22 Premium F SI1 60.4 61.0 342 3.88 3.84 2.33 #&gt; 4 0.20 Premium E SI2 60.2 62.0 345 3.79 3.75 2.27 #&gt; 5 0.32 Premium E I1 60.9 58.0 345 4.38 4.42 2.68 #&gt; 6 0.24 Premium I VS1 62.5 57.0 355 3.97 3.94 2.47 #&gt; 7 0.29 Premium F SI1 62.4 58.0 403 4.24 4.26 2.65 #&gt; 8 0.22 Premium E VS2 61.6 58.0 404 3.93 3.89 2.41 #&gt; 9 0.22 Premium D VS2 59.3 62.0 404 3.91 3.88 2.31 #&gt; 10 0.30 Premium J SI2 59.3 61.0 405 4.43 4.38 2.61 #&gt; [ reached getOption(&quot;max.print&quot;) -- omitted 6390 rows ] We can confirm that we get the same subset in R: nrow(premium_diamonds) #&gt; [1] 6400 nrow(subset(ggplot2::diamonds, cut == &quot;Premium&quot; &amp; price &lt; 1000)) #&gt; [1] 3200 To learn more about mongo data queries, study the Mongo Query Documents manual. 3.2 Filter fields The fields parameter filters specific columns from the output. Let’s continue our example above: test &lt;- dmd$find( query = &#39;{&quot;cut&quot; : &quot;Premium&quot;, &quot;price&quot; : { &quot;$lt&quot; : 1000 } }&#39;, fields = &#39;{&quot;cut&quot; : true, &quot;clarity&quot; : true}&#39;, limit = 5 ) print(test) #&gt; _id cut clarity #&gt; 1 5b636b1847a3020d441129ac Premium SI1 #&gt; 2 5b636b1847a3020d441129ae Premium VS2 #&gt; 3 5b636b1847a3020d441129b7 Premium SI1 #&gt; 4 5b636b1847a3020d441129b9 Premium SI2 #&gt; 5 5b636b1847a3020d441129ba Premium I1 By default mongo always includes the id field. To prevent this we need to explicitly disable it: test &lt;- dmd$find( query = &#39;{&quot;cut&quot; : &quot;Premium&quot;, &quot;price&quot; : { &quot;$lt&quot; : 1000 } }&#39;, fields = &#39;{&quot;cut&quot; : true, &quot;clarity&quot; : true, &quot;_id&quot;: false}&#39;, limit = 5 ) print(test) #&gt; cut clarity #&gt; 1 Premium SI1 #&gt; 2 Premium VS2 #&gt; 3 Premium SI1 #&gt; 4 Premium SI2 #&gt; 5 Premium I1 The default value for the field argument is '{&quot;_id&quot; : 0}' i.e. all columns, except for _id. 3.3 Sort and limit The sort parameter allows us to order the output, and limit restricts the number records that will be returned. For example to return the 7 most expensive premium diamonds in the data we sort by price in descending order: dmd$find(&#39;{&quot;cut&quot; : &quot;Premium&quot;}&#39;, sort = &#39;{&quot;price&quot;: -1}&#39;, limit = 7) #&gt; carat cut color clarity depth table price x y z #&gt; 1 2.29 Premium I VS2 60.8 60 18823 8.50 8.47 5.16 #&gt; 2 2.29 Premium I VS2 60.8 60 18823 8.50 8.47 5.16 #&gt; 3 2.29 Premium I SI1 61.8 59 18797 8.52 8.45 5.24 #&gt; 4 2.29 Premium I SI1 61.8 59 18797 8.52 8.45 5.24 #&gt; 5 2.04 Premium H SI1 58.1 60 18795 8.37 8.28 4.84 #&gt; 6 2.00 Premium I VS1 60.8 59 18795 8.13 8.02 4.91 #&gt; 7 2.04 Premium H SI1 58.1 60 18795 8.37 8.28 4.84 Note that usually you should only sort by fields that have an index set on them. Sorting by unindexed fields can be very slow and the server might reach the memory limits on the server. 3.4 Indexing By default a collection only has an index for _id, which means that selecting or sorting by any other field is relatively slow. system.time(dmd$find(sort = &#39;{&quot;price&quot; : 1}&#39;, limit = 1)) #&gt; user system elapsed #&gt; 0.002 0.000 0.189 By adding an index, the field gets presorted and selecting or sorting it is almost immediate: dmd$index(add = &#39;{&quot;price&quot; : 1}&#39;) #&gt; v key._id key.price name ns #&gt; 1 2 1 NA _id_ test.diamonds #&gt; 2 2 NA 1 price_1 test.diamonds system.time(dmd$find(sort = &#39;{&quot;price&quot; : 1}&#39;, limit = 1)) #&gt; user system elapsed #&gt; 0.001 0.000 0.002 In order to speed up queries involving multiple fields, you need to add a cross-index which intersects both fields: dmd$index(add = &#39;{&quot;depth&quot; : 1}&#39;) #&gt; v key._id key.price key.depth name ns #&gt; 1 2 1 NA NA _id_ test.diamonds #&gt; 2 2 NA 1 NA price_1 test.diamonds #&gt; 3 2 NA NA 1 depth_1 test.diamonds dmd$index(add = &#39;{&quot;depth&quot; : 1, &quot;price&quot; : 1}&#39;) #&gt; v key._id key.price key.depth name ns #&gt; 1 2 1 NA NA _id_ test.diamonds #&gt; 2 2 NA 1 NA price_1 test.diamonds #&gt; 3 2 NA NA 1 depth_1 test.diamonds #&gt; 4 2 NA 1 1 depth_1_price_1 test.diamonds To remove indices from the collection, use the name as listed above: dmd$index(remove = &#39;depth_1_price_1&#39;) #&gt; v key._id key.price key.depth name ns #&gt; 1 2 1 NA NA _id_ test.diamonds #&gt; 2 2 NA 1 NA price_1 test.diamonds #&gt; 3 2 NA NA 1 depth_1 test.diamonds dmd$index(remove = &#39;depth_1&#39;) #&gt; v key._id key.price name ns #&gt; 1 2 1 NA _id_ test.diamonds #&gt; 2 2 NA 1 price_1 test.diamonds 3.5 Iterating The find() method automatically simplifies the collection into a data frame, but sometimes you need more fine-grained control. The iterate() method allows you to perform a query, but read the records one-by-one without simplification. The iterator has methods one(), batch(n) which allow you to step through a single or n records at the time. When the iterator is exhausted it will return NULL. Lets run the same query as above using the iterator interface: # perform query and return the iterator it &lt;- dmd$iterate(&#39;{&quot;cut&quot; : &quot;Premium&quot;}&#39;, sort = &#39;{&quot;price&quot;: -1}&#39;, limit = 7) # read records from the iterator while(!is.null(x &lt;- it$one())){ cat(sprintf(&quot;Found %.2f carat diamond for $%d\\n&quot;, x$carat, x$price)) } #&gt; Found 2.29 carat diamond for $18823 #&gt; Found 2.29 carat diamond for $18823 #&gt; Found 2.29 carat diamond for $18797 #&gt; Found 2.29 carat diamond for $18797 #&gt; Found 2.00 carat diamond for $18795 #&gt; Found 2.04 carat diamond for $18795 #&gt; Found 2.00 carat diamond for $18795 The iterator does not perform any simplification, so each x is simply a named list containing the parsed JSON record. 3.6 Select by date In order to query by timestamp we must make sure dates are in proper UTC datetime format. When inserting data via R this means the column must be in POSIXct type. # Get some example data mydata &lt;- jsonlite::fromJSON(&quot;https://api.github.com/repos/jeroen/mongolite/issues&quot;) mydata$title &lt;- paste0(substr(mydata$title, 1, 40), &quot;...&quot;) mydata$created_at &lt;- strptime(mydata$created_at, &quot;%Y-%m-%dT%H:%M:%SZ&quot;, &#39;UTC&#39;) mydata$closed_at &lt;- strptime(mydata$closed_at, &quot;%Y-%m-%dT%H:%M:%SZ&quot;, &#39;UTC&#39;) # Insert into mongo issues &lt;- mongo(&quot;issues&quot;) issues$insert(mydata) #&gt; List of 5 #&gt; $ nInserted : num 30 #&gt; $ nMatched : num 0 #&gt; $ nRemoved : num 0 #&gt; $ nUpserted : num 0 #&gt; $ writeErrors: list() Selecting by date is done via the &quot;$date&quot; operator. For example to select dates which were created after January 1st, 2017: issues$find( query = &#39;{&quot;created_at&quot;: { &quot;$gte&quot; : { &quot;$date&quot; : &quot;2017-01-01T00:00:00Z&quot; }}}&#39;, fields = &#39;{&quot;created_at&quot; : true, &quot;user.login&quot; : true, &quot;title&quot;:true, &quot;_id&quot;: false}&#39; ) #&gt; title login created_at #&gt; 1 Moves to canonical extended JSON output... atheriel 2018-08-02 00:27:48 #&gt; 2 Updates the specification tests to match... atheriel 2018-08-01 21:28:49 #&gt; 3 Request for Query Modifiers... DavidHeslip 2018-07-24 12:23:27 #&gt; 4 fixed json default parameter in run func... LRAbbade 2018-07-11 16:27:03 #&gt; 5 Why can not I install mongolite packages... ChangMinSeung 2018-07-07 06:24:32 #&gt; 6 Error: Unimplemented BSON type 14 ... stevepetersen 2018-07-01 03:50:14 #&gt; 7 Add database name to mongo info function... Serenthia 2018-06-22 18:19:37 #&gt; 8 Get database name of a connection to a n... Serenthia 2018-06-21 23:54:15 #&gt; 9 How to write R NULL value in Mongo?... gonzalezivan90 2018-06-21 22:41:51 #&gt; 10 How do I close the connection with mongo... brunoroquette 2018-06-05 18:47:20 #&gt; 11 decimals rounding issue... tomfid1983 2018-05-21 18:49:04 #&gt; 12 Looking for document to show sample abou... psramkumar 2018-05-18 11:00:49 #&gt; 13 How do I create a unique index?... bidwbb 2018-04-19 19:55:22 #&gt; 14 undefined symbol: _mongoc_linux_distro_s... jet456 2018-04-18 20:09:04 #&gt; 15 Installation failure in alpine linux (Do... blmayer 2018-04-13 22:11:43 #&gt; 16 Mongolite connection just stop working.... gliesian-llc 2018-04-02 15:39:50 #&gt; 17 Get information from GridFS... FidelCastillo 2018-03-23 10:49:28 #&gt; 18 Documentation doesn&#39;t match implementati... joerixaop 2018-02-19 17:10:01 #&gt; 19 No error on broken connection... jeroen 2018-01-29 14:39:03 #&gt; 20 Remove mongolab references... rlondner 2018-01-11 20:17:44 #&gt; 21 Unable to install: missing zlib.h file... rodgersk410 2018-01-02 21:51:11 #&gt; 22 Reusing the same connection for several ... mredaelli 2017-12-29 11:56:17 #&gt; 23 Insert issue with numeric rownames... jcaude 2017-09-29 11:25:50 #&gt; 24 Request return type as JSON instead of d... xiaodaigh 2017-09-25 15:51:37 #&gt; 25 When do a find() I get Error: Elements n... xiaodaigh 2017-09-19 13:29:57 #&gt; 26 Is possible to support connection pool?... smartguo 2017-08-29 04:34:07 #&gt; 27 Query Issue with Aggregation ... koushiksaha89 2017-05-25 09:52:11 #&gt; 28 colum has arraylist... yueming-Chen 2017-05-04 06:25:33 #&gt; 29 Adding NaN and Infinity values to databa... LauraPalas 2017-04-20 18:20:16 #&gt; 30 How to &quot;show databases&quot; and &quot;show collec... kingsnakexxx 2017-03-31 04:05:58 #&gt; 31 Moves to canonical extended JSON output... atheriel 2018-08-02 00:27:48 #&gt; 32 Updates the specification tests to match... atheriel 2018-08-01 21:28:49 #&gt; 33 Request for Query Modifiers... DavidHeslip 2018-07-24 12:23:27 #&gt; [ reached getOption(&quot;max.print&quot;) -- omitted 27 rows ] Note that confusingly, what R calls a Date is not a timestamp but rather a string which only contains the date (Y-M-D) part of a timestamp. This type cannot be queried in MongoDB. See the MongoDB Extended JSON manual for details. 3.7 Select by ID Each record inserted into MongoDB is automatically assigned an &quot;_id&quot; value. issues$find(fields= &#39;{&quot;created_at&quot;:true, &quot;_id&quot;:true}&#39;, limit = 10) #&gt; _id created_at #&gt; 1 5b636b1d47a3020d4411fc60 2018-08-02 00:27:48 #&gt; 2 5b636b1d47a3020d4411fc61 2018-08-01 21:28:49 #&gt; 3 5b636b1d47a3020d4411fc62 2018-07-24 12:23:27 #&gt; 4 5b636b1d47a3020d4411fc63 2018-07-11 16:27:03 #&gt; 5 5b636b1d47a3020d4411fc64 2018-07-07 06:24:32 #&gt; 6 5b636b1d47a3020d4411fc65 2018-07-01 03:50:14 #&gt; 7 5b636b1d47a3020d4411fc66 2018-06-22 18:19:37 #&gt; 8 5b636b1d47a3020d4411fc67 2018-06-21 23:54:15 #&gt; 9 5b636b1d47a3020d4411fc68 2018-06-21 22:41:51 #&gt; 10 5b636b1d47a3020d4411fc69 2018-06-05 18:47:20 Use the {&quot;$oid&quot;} operator (similar to ObjectId() in mongo) to select a record by it’s ID, for example: issues$find(query = &#39;{&quot;_id&quot; : {&quot;$oid&quot;:&quot;58a83a6aba7cb2070210433e&quot;}}&#39;) See the MongoDB Extended JSON manual for syntax details. "],
["manipulate-data.html", "Chapter 4 Manipulate Data 4.1 Insert 4.2 Remove 4.3 Update / Upsert 4.4 Array Filters", " Chapter 4 Manipulate Data 4.1 Insert The easiest way to insert data is from an R data frame. The data frame columns will automatically be mapped to keys in the JSON records: test &lt;- mongo() test$drop() test$insert(iris) #&gt; List of 5 #&gt; $ nInserted : num 150 #&gt; $ nMatched : num 0 #&gt; $ nRemoved : num 0 #&gt; $ nUpserted : num 0 #&gt; $ writeErrors: list() This is basically the inverse from mongo$find() which converts the collection back into a Data Frame: test$find(limit = 5) #&gt; Sepal_Length Sepal_Width Petal_Length Petal_Width Species #&gt; 1 5.1 3.5 1.4 0.2 setosa #&gt; 2 4.9 3.0 1.4 0.2 setosa #&gt; 3 4.7 3.2 1.3 0.2 setosa #&gt; 4 4.6 3.1 1.5 0.2 setosa #&gt; 5 5.0 3.6 1.4 0.2 setosa Records can also be inserted directly as JSON strings. This requires a character vector where each element is a valid JSON string. subjects &lt;- mongo(&quot;subjects&quot;) str &lt;- c(&#39;{&quot;name&quot; : &quot;jerry&quot;}&#39; , &#39;{&quot;name&quot;: &quot;anna&quot;, &quot;age&quot; : 23}&#39;, &#39;{&quot;name&quot;: &quot;joe&quot;}&#39;) subjects$insert(str) #&gt; List of 6 #&gt; $ nInserted : int 3 #&gt; $ nMatched : int 0 #&gt; $ nModified : int 0 #&gt; $ nRemoved : int 0 #&gt; $ nUpserted : int 0 #&gt; $ writeErrors: list() subjects$find(query = &#39;{}&#39;, fields = &#39;{}&#39;) #&gt; _id name age has_age #&gt; 1 5b636b1d47a3020d4411fd16 jerry 31 TRUE #&gt; 2 5b636b1d47a3020d4411fd17 anna 23 TRUE #&gt; 3 5b636b1d47a3020d4411fd18 joe NA FALSE #&gt; 4 5b636b1d154c82af8275bc7d erik 29 NA #&gt; 5 5b636b7a47a3020d7336df96 jerry NA NA #&gt; 6 5b636b7a47a3020d7336df97 anna 23 NA #&gt; 7 5b636b7a47a3020d7336df98 joe NA NA Obviously you can generate such JSON records dynamically from data via e.g. jsonlite::toJSON. 4.2 Remove The same syntax that we use in find() to select records for reading, can also be used to select records for deleting: test$count() #&gt; [1] 150 test$remove(&#39;{&quot;Species&quot; : &quot;setosa&quot;}&#39;) test$count() #&gt; [1] 100 Use the just_one option to delete a single record: test$remove(&#39;{&quot;Sepal_Length&quot; : {&quot;$lte&quot; : 5}}&#39;, just_one = TRUE) test$count() #&gt; [1] 99 To delete all records in the collection (but not the collection itself): test$remove(&#39;{}&#39;) test$count() #&gt; [1] 0 The drop() operator will delete an entire collection. This includes all data, as well as metadata such as collection indices. test$drop() 4.3 Update / Upsert To modify existing records, use the update() operator: subjects$find() #&gt; name age has_age #&gt; 1 jerry 31 TRUE #&gt; 2 anna 23 TRUE #&gt; 3 joe NA FALSE #&gt; 4 erik 29 NA #&gt; 5 jerry NA NA #&gt; 6 anna 23 NA #&gt; 7 joe NA NA subjects$update(&#39;{&quot;name&quot;:&quot;jerry&quot;}&#39;, &#39;{&quot;$set&quot;:{&quot;age&quot;: 31}}&#39;) #&gt; List of 3 #&gt; $ modifiedCount: int 0 #&gt; $ matchedCount : int 1 #&gt; $ upsertedCount: int 0 subjects$find() #&gt; name age has_age #&gt; 1 jerry 31 TRUE #&gt; 2 anna 23 TRUE #&gt; 3 joe NA FALSE #&gt; 4 erik 29 NA #&gt; 5 jerry NA NA #&gt; 6 anna 23 NA #&gt; 7 joe NA NA By default, the update() method updates a single document. To update multiple documents, use the multi option in the update() method. subjects$update(&#39;{}&#39;, &#39;{&quot;$set&quot;:{&quot;has_age&quot;: false}}&#39;, multiple = TRUE) #&gt; List of 3 #&gt; $ modifiedCount: int 6 #&gt; $ matchedCount : int 7 #&gt; $ upsertedCount: int 0 subjects$update(&#39;{&quot;age&quot; : {&quot;$gte&quot; : 0}}&#39;, &#39;{&quot;$set&quot;:{&quot;has_age&quot;: true}}&#39;, multiple = TRUE) #&gt; List of 3 #&gt; $ modifiedCount: int 4 #&gt; $ matchedCount : int 4 #&gt; $ upsertedCount: int 0 subjects$find() #&gt; name age has_age #&gt; 1 jerry 31 TRUE #&gt; 2 anna 23 TRUE #&gt; 3 joe NA FALSE #&gt; 4 erik 29 TRUE #&gt; 5 jerry NA FALSE #&gt; 6 anna 23 TRUE #&gt; 7 joe NA FALSE If no document matches the update condition, the default behavior of the update method is to do nothing. By specifying the upsert option to true, the update operation either updates matching document(s) or inserts a new document if no matching document exists. subjects$update(&#39;{&quot;name&quot;:&quot;erik&quot;}&#39;, &#39;{&quot;$set&quot;:{&quot;age&quot;: 29}}&#39;, upsert = TRUE) #&gt; List of 3 #&gt; $ modifiedCount: int 0 #&gt; $ matchedCount : int 1 #&gt; $ upsertedCount: int 0 subjects$find() #&gt; name age has_age #&gt; 1 jerry 31 TRUE #&gt; 2 anna 23 TRUE #&gt; 3 joe NA FALSE #&gt; 4 erik 29 TRUE #&gt; 5 jerry NA FALSE #&gt; 6 anna 23 TRUE #&gt; 7 joe NA FALSE 4.4 Array Filters Starting in MongoDB 3.6, when updating an array field, you can specify arrayFilters that determine which array elements to update. students &lt;- mongo(&quot;students&quot;) students$insert(c( &#39;{ &quot;student&quot; : 1, &quot;grades&quot; : [ 95, 92, 90 ] }&#39;, &#39;{ &quot;student&quot; : 2, &quot;grades&quot; : [ 98, 100, 102 ] }&#39;, &#39;{ &quot;student&quot; : 3, &quot;grades&quot; : [ 95, 110, 100] }&#39;)) #&gt; List of 6 #&gt; $ nInserted : int 3 #&gt; $ nMatched : int 0 #&gt; $ nModified : int 0 #&gt; $ nRemoved : int 0 #&gt; $ nUpserted : int 0 #&gt; $ writeErrors: list() students$find() #&gt; student grades #&gt; 1 1 95, 92, 90 #&gt; 2 2 98, 100, 102 #&gt; 3 3 95, 110, 100 To modify all elements that are greater than or equal to 100 in the grades array, use the filtered positional operator $[&lt;identifier&gt;] in the filters parameter: students$update(query = &#39;{}&#39;, update = &#39;{&quot;$set&quot;:{&quot;grades.$[element]&quot;:100}}&#39;, filters = &#39;[{&quot;element&quot;: {&quot;$gte&quot;:100}}]&#39;, multiple = TRUE) #&gt; List of 3 #&gt; $ modifiedCount: int 2 #&gt; $ matchedCount : int 3 #&gt; $ upsertedCount: int 0 students$find() #&gt; student grades #&gt; 1 1 95, 92, 90 #&gt; 2 2 98, 100, 100 #&gt; 3 3 95, 100, 100 "],
["import-export.html", "Chapter 5 Import / Export 5.1 JSON 5.2 Via jsonlite 5.3 Streaming 5.4 BSON", " Chapter 5 Import / Export The import() and export() methods are used to read / write collection dumps via a connection, such as a file, socket or URL. 5.1 JSON The default format for is newline delimited JSON lines, i.e. one line for each record (aka NDJSON) subjects$export(stdout()) #&gt; { &quot;_id&quot; : { &quot;$oid&quot; : &quot;5b636b1d154c82af8275bc7d&quot; }, &quot;name&quot; : &quot;erik&quot;, &quot;age&quot; : 29, &quot;has_age&quot; : true } #&gt; { &quot;_id&quot; : { &quot;$oid&quot; : &quot;5b636b1d47a3020d4411fd16&quot; }, &quot;name&quot; : &quot;jerry&quot;, &quot;age&quot; : 31, &quot;has_age&quot; : true } #&gt; { &quot;_id&quot; : { &quot;$oid&quot; : &quot;5b636b1d47a3020d4411fd17&quot; }, &quot;name&quot; : &quot;anna&quot;, &quot;age&quot; : 23, &quot;has_age&quot; : true } #&gt; { &quot;_id&quot; : { &quot;$oid&quot; : &quot;5b636b1d47a3020d4411fd18&quot; }, &quot;name&quot; : &quot;joe&quot;, &quot;has_age&quot; : false } #&gt; { &quot;_id&quot; : { &quot;$oid&quot; : &quot;5b636b7a47a3020d7336df96&quot; }, &quot;name&quot; : &quot;jerry&quot;, &quot;has_age&quot; : false } #&gt; { &quot;_id&quot; : { &quot;$oid&quot; : &quot;5b636b7a47a3020d7336df97&quot; }, &quot;name&quot; : &quot;anna&quot;, &quot;age&quot; : 23, &quot;has_age&quot; : true } #&gt; { &quot;_id&quot; : { &quot;$oid&quot; : &quot;5b636b7a47a3020d7336df98&quot; }, &quot;name&quot; : &quot;joe&quot;, &quot;has_age&quot; : false } Usually we will export to a file: dmd$export(file(&quot;dump.json&quot;)) Let’s test this by removing the entire collection, and then importing it back from the file: dmd$drop() dmd$count() #&gt; [1] 0 dmd$import(file(&quot;dump.json&quot;)) dmd$count() #&gt; [1] 107880 5.2 Via jsonlite The jsonlite package also allows for importing/exporting the NDJSON format directly in R via the stream_in and stream_out methods: mydata &lt;- jsonlite::stream_in(file(&quot;dump.json&quot;), verbose = FALSE) print(mydata) #&gt; $oid carat cut color clarity depth table price x y z #&gt; 1 5b636b1847a3020d441129ab 0.23 Ideal E SI2 61.5 55.0 326 3.95 3.98 2.43 #&gt; 2 5b636b1847a3020d441129ac 0.21 Premium E SI1 59.8 61.0 326 3.89 3.84 2.31 #&gt; 3 5b636b1847a3020d441129ad 0.23 Good E VS1 56.9 65.0 327 4.05 4.07 2.31 #&gt; 4 5b636b1847a3020d441129ae 0.29 Premium I VS2 62.4 58.0 334 4.20 4.23 2.63 #&gt; 5 5b636b1847a3020d441129af 0.31 Good J SI2 63.3 58.0 335 4.34 4.35 2.75 #&gt; 6 5b636b1847a3020d441129b0 0.24 Very Good J VVS2 62.8 57.0 336 3.94 3.96 2.48 #&gt; 7 5b636b1847a3020d441129b1 0.24 Very Good I VVS1 62.3 57.0 336 3.95 3.98 2.47 #&gt; 8 5b636b1847a3020d441129b2 0.26 Very Good H SI1 61.9 55.0 337 4.07 4.11 2.53 #&gt; 9 5b636b1847a3020d441129b3 0.22 Fair E VS2 65.1 61.0 337 3.87 3.78 2.49 #&gt; [ reached getOption(&quot;max.print&quot;) -- omitted 107871 rows ] This is a convenient way to exchange data in a way with R users that might not have MongoDB. Similarly jsonlite allows for exporting data in a way that is easy to import in Mongo: jsonlite::stream_out(mtcars, file(&quot;mtcars.json&quot;), verbose = FALSE) mt &lt;- mongo(&quot;mtcars&quot;) mt$import(file(&quot;mtcars.json&quot;)) mt$find() #&gt; Warning: Duplicate names in &quot;_row&quot; field. Data frames must have unique row names. #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 #&gt; Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 #&gt; Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 #&gt; Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 #&gt; Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 #&gt; Valiant 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 #&gt; Duster 360 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 #&gt; Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 #&gt; Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 #&gt; [ reached getOption(&quot;max.print&quot;) -- omitted 55 rows ] 5.3 Streaming Both mongolite and jsonlite also allow for importing NDJSON data from a HTTP stream: flt &lt;- mongo(&quot;flights&quot;) flt$import(gzcon(curl::curl(&quot;https://jeroen.github.io/data/nycflights13.json.gz&quot;))) flt$count() #&gt; [1] 673552 The same operation in jsonlite would be: flights &lt;- jsonlite::stream_in( gzcon(curl::curl(&quot;https://jeroen.github.io/data/nycflights13.json.gz&quot;)), verbose = FALSE) nrow(flights) #&gt; [1] 336776 5.4 BSON MongoDB internally stores data in BSON format, which is a binary version of JSON. Use the bson parameter to dump a collection directly in BSON format: flt$export(file(&quot;flights.bson&quot;), bson = TRUE) Same to read it back: flt$drop() flt$import(file(&quot;flights.bson&quot;), bson = TRUE) #&gt; [1] 673552 flt$find(limit = 5) #&gt; year month day dep_time dep_delay arr_time arr_delay carrier tailnum flight origin dest air_time distance hour minute #&gt; 1 2013 1 1 517 2 830 11 UA N14228 1545 EWR IAH 227 1400 5 17 #&gt; 2 2013 1 1 533 4 850 20 UA N24211 1714 LGA IAH 227 1416 5 33 #&gt; 3 2013 1 1 542 2 923 33 AA N619AA 1141 JFK MIA 160 1089 5 42 #&gt; 4 2013 1 1 544 -1 1004 -18 B6 N804JB 725 JFK BQN 183 1576 5 44 #&gt; 5 2013 1 1 554 -6 812 -25 DL N668DN 461 LGA ATL 116 762 5 54 Using BSON to import/export is faster than JSON, but the resulting file can only be read by MongoDB. "],
["calculation.html", "Chapter 6 Calculation 6.1 Aggregate 6.2 Map/Reduce", " Chapter 6 Calculation MongoDB has two methods for performing in-database calculations: aggregation pipelines and mapreduce. The aggregation pipeline system provides better performance and more coherent interface. However, map-reduce operations provide some flexibility that is not presently available in the aggregation pipeline. 6.1 Aggregate The aggregate() method allows you to run an aggregation pipeline. For example the pipeline below calculates the total flights per carrier and the average distance: stats &lt;- flt$aggregate( &#39;[{&quot;$group&quot;:{&quot;_id&quot;:&quot;$carrier&quot;, &quot;count&quot;: {&quot;$sum&quot;:1}, &quot;average&quot;:{&quot;$avg&quot;:&quot;$distance&quot;}}}]&#39;, options = &#39;{&quot;allowDiskUse&quot;:true}&#39; ) names(stats) &lt;- c(&quot;carrier&quot;, &quot;count&quot;, &quot;average&quot;) print(stats) #&gt; carrier count average #&gt; 1 OO 64 500.8125 #&gt; 2 F9 1370 1620.0000 #&gt; 3 YV 1202 375.0333 #&gt; 4 EV 108346 562.9917 #&gt; 5 FL 6520 664.8294 #&gt; 6 9E 36920 530.2358 #&gt; 7 AS 1428 2402.0000 #&gt; 8 US 41072 553.4563 #&gt; 9 MQ 52794 569.5327 #&gt; 10 UA 117330 1529.1149 #&gt; 11 DL 96220 1236.9012 #&gt; 12 B6 109270 1068.6215 #&gt; 13 VX 10324 2499.4822 #&gt; 14 WN 24550 996.2691 #&gt; 15 HA 684 4983.0000 #&gt; 16 AA 65458 1340.2360 Let’s make a pretty plot: library(ggplot2) ggplot(aes(carrier, count), data = stats) + geom_col() Check the MongoDB manual for detailed description of the pipeline syntax and supported options. 6.2 Map/Reduce The mapreduce() method allow for running a custom in-database mapreduce job by providing custom map and reduce JavaScript functions. Running JavaScript is slower using the aggregate system, but you can implement fully customized database operations. Below is a simple example to do “binning” of distances to create a histogram. # Map-reduce (binning) histdata &lt;- flt$mapreduce( map = &quot;function(){emit(Math.floor(this.distance/100)*100, 1)}&quot;, reduce = &quot;function(id, counts){return Array.sum(counts)}&quot; ) names(histdata) &lt;- c(&quot;distance&quot;, &quot;count&quot;) print(histdata) #&gt; distance count #&gt; 1 0 3266 #&gt; 2 100 32034 #&gt; 3 200 67274 #&gt; 4 300 15496 #&gt; 5 400 42364 #&gt; 6 500 53850 #&gt; 7 600 15692 #&gt; 8 700 97808 #&gt; 9 800 15148 #&gt; 10 900 36410 #&gt; 11 1000 98654 #&gt; 12 1100 12672 #&gt; 13 1200 664 #&gt; 14 1300 18168 #&gt; 15 1400 18626 #&gt; 16 1500 17546 #&gt; 17 1600 18440 #&gt; 18 1700 486 #&gt; 19 1800 630 #&gt; 20 1900 4934 #&gt; 21 2100 9312 #&gt; 22 2200 11994 #&gt; 23 2300 38 #&gt; 24 2400 52104 #&gt; 25 2500 28512 #&gt; 26 3300 16 #&gt; 27 4900 1414 From this data we can create a pretty histogram: library(ggplot2) ggplot(aes(distance, count), data = histdata) + geom_col() Obviously we could have done binning in R instead, however if we are dealing with loads of data, doing it in database can be much more efficient. "],
["server-tools.html", "Chapter 7 Server Tools 7.1 Running Commands 7.2 Server Info", " Chapter 7 Server Tools 7.1 Running Commands For mongodb operations that mongolite currently does not implement, you can still use the raw database command using the run() method: col &lt;- mongo() col$run(&#39;{&quot;ping&quot;: 1}&#39;) #&gt; $ok #&gt; [1] 1 str(col$run(&#39;{&quot;listCollections&quot;:1}&#39;)) #&gt; List of 2 #&gt; $ cursor:List of 3 #&gt; ..$ id : num 0 #&gt; ..$ ns : chr &quot;test.$cmd.listCollections&quot; #&gt; ..$ firstBatch:List of 5 #&gt; .. ..$ :List of 5 #&gt; .. .. ..$ name : chr &quot;mtcars&quot; #&gt; .. .. ..$ type : chr &quot;collection&quot; #&gt; .. .. ..$ options: Named list() #&gt; .. .. ..$ info :List of 2 #&gt; .. .. .. ..$ readOnly: logi FALSE #&gt; .. .. .. ..$ uuid : raw [1:16] c2 36 7b 65 ... #&gt; .. .. .. .. ..- attr(*, &quot;type&quot;)= raw 04 #&gt; .. .. ..$ idIndex:List of 4 #&gt; .. .. .. ..$ v : int 2 #&gt; .. .. .. ..$ key :List of 1 #&gt; .. .. .. .. ..$ _id: int 1 #&gt; .. .. .. ..$ name: chr &quot;_id_&quot; #&gt; .. .. .. ..$ ns : chr &quot;test.mtcars&quot; #&gt; .. ..$ :List of 5 #&gt; .. .. ..$ name : chr &quot;flights&quot; #&gt; .. .. ..$ type : chr &quot;collection&quot; #&gt; .. .. ..$ options: Named list() #&gt; .. .. ..$ info :List of 2 #&gt; .. .. .. ..$ readOnly: logi FALSE #&gt; .. .. .. ..$ uuid : raw [1:16] cc c3 2b e3 ... #&gt; .. .. .. .. ..- attr(*, &quot;type&quot;)= raw 04 #&gt; .. .. ..$ idIndex:List of 4 #&gt; .. .. .. ..$ v : int 2 #&gt; .. .. .. ..$ key :List of 1 #&gt; .. .. .. .. ..$ _id: int 1 #&gt; .. .. .. ..$ name: chr &quot;_id_&quot; #&gt; .. .. .. ..$ ns : chr &quot;test.flights&quot; #&gt; .. ..$ :List of 5 #&gt; .. .. ..$ name : chr &quot;issues&quot; #&gt; .. .. ..$ type : chr &quot;collection&quot; #&gt; .. .. ..$ options: Named list() #&gt; .. .. ..$ info :List of 2 #&gt; .. .. .. ..$ readOnly: logi FALSE #&gt; .. .. .. ..$ uuid : raw [1:16] d5 72 54 c5 ... #&gt; .. .. .. .. ..- attr(*, &quot;type&quot;)= raw 04 #&gt; .. .. ..$ idIndex:List of 4 #&gt; .. .. .. ..$ v : int 2 #&gt; .. .. .. ..$ key :List of 1 #&gt; .. .. .. .. ..$ _id: int 1 #&gt; .. .. .. ..$ name: chr &quot;_id_&quot; #&gt; .. .. .. ..$ ns : chr &quot;test.issues&quot; #&gt; .. ..$ :List of 5 #&gt; .. .. ..$ name : chr &quot;subjects&quot; #&gt; .. .. ..$ type : chr &quot;collection&quot; #&gt; .. .. ..$ options: Named list() #&gt; .. .. ..$ info :List of 2 #&gt; .. .. .. ..$ readOnly: logi FALSE #&gt; .. .. .. ..$ uuid : raw [1:16] 5f be 09 df ... #&gt; .. .. .. .. ..- attr(*, &quot;type&quot;)= raw 04 #&gt; .. .. ..$ idIndex:List of 4 #&gt; .. .. .. ..$ v : int 2 #&gt; .. .. .. ..$ key :List of 1 #&gt; .. .. .. .. ..$ _id: int 1 #&gt; .. .. .. ..$ name: chr &quot;_id_&quot; #&gt; .. .. .. ..$ ns : chr &quot;test.subjects&quot; #&gt; .. ..$ :List of 5 #&gt; .. .. ..$ name : chr &quot;diamonds&quot; #&gt; .. .. ..$ type : chr &quot;collection&quot; #&gt; .. .. ..$ options: Named list() #&gt; .. .. ..$ info :List of 2 #&gt; .. .. .. ..$ readOnly: logi FALSE #&gt; .. .. .. ..$ uuid : raw [1:16] a8 e2 1c ae ... #&gt; .. .. .. .. ..- attr(*, &quot;type&quot;)= raw 04 #&gt; .. .. ..$ idIndex:List of 4 #&gt; .. .. .. ..$ v : int 2 #&gt; .. .. .. ..$ key :List of 1 #&gt; .. .. .. .. ..$ _id: int 1 #&gt; .. .. .. ..$ name: chr &quot;_id_&quot; #&gt; .. .. .. ..$ ns : chr &quot;test.diamonds&quot; #&gt; $ ok : num 1 Some commands can only be run on the admin database: admin &lt;- mongo(db = &quot;admin&quot;) str(admin$run(&#39;{&quot;listDatabases&quot;:1}&#39;)) #&gt; List of 3 #&gt; $ databases:List of 4 #&gt; ..$ :List of 3 #&gt; .. ..$ name : chr &quot;admin&quot; #&gt; .. ..$ sizeOnDisk: num 32768 #&gt; .. ..$ empty : logi FALSE #&gt; ..$ :List of 3 #&gt; .. ..$ name : chr &quot;config&quot; #&gt; .. ..$ sizeOnDisk: num 73728 #&gt; .. ..$ empty : logi FALSE #&gt; ..$ :List of 3 #&gt; .. ..$ name : chr &quot;local&quot; #&gt; .. ..$ sizeOnDisk: num 65536 #&gt; .. ..$ empty : logi FALSE #&gt; ..$ :List of 3 #&gt; .. ..$ name : chr &quot;test&quot; #&gt; .. ..$ sizeOnDisk: num 14524416 #&gt; .. ..$ empty : logi FALSE #&gt; $ totalSize: num 14696448 #&gt; $ ok : num 1 7.2 Server Info Some server information is available in the $info() method: col$info() #&gt; List of 3 #&gt; $ collection: chr &quot;test&quot; #&gt; $ stats : NULL #&gt; $ server :List of 25 #&gt; ..$ host : chr &quot;Jeroens-MBP.fritz.box&quot; #&gt; ..$ version : chr &quot;4.0.0&quot; #&gt; ..$ process : chr &quot;mongod&quot; #&gt; ..$ pid : num 799 #&gt; ..$ uptime : num 6973 #&gt; ..$ uptimeMillis : num 6972881 #&gt; ..$ uptimeEstimate : num 6972 #&gt; ..$ localTime : POSIXct[1:1], format: &quot;2018-08-02 22:38:23&quot; #&gt; ..$ asserts :List of 5 #&gt; ..$ connections :List of 3 #&gt; ..$ extra_info :List of 2 #&gt; ..$ freeMonitoring :List of 1 #&gt; ..$ globalLock :List of 3 #&gt; ..$ locks :List of 3 #&gt; ..$ logicalSessionRecordCache:List of 11 #&gt; ..$ network :List of 7 #&gt; ..$ opLatencies :List of 3 #&gt; ..$ opcounters :List of 6 #&gt; ..$ opcountersRepl :List of 6 #&gt; ..$ storageEngine :List of 5 #&gt; ..$ transactions :List of 3 #&gt; ..$ wiredTiger :List of 17 #&gt; ..$ mem :List of 6 #&gt; ..$ metrics :List of 10 #&gt; ..$ ok : num 1 "],
["gridfs.html", "Chapter 8 GridFS 8.1 Connecting to GridFS 8.2 GridFS Methods 8.3 Read / Write 8.4 Vectorized Upload/Download", " Chapter 8 GridFS A recent addition to mongolite is support for GridFS. A GridFS is a special type of collection for storing binary data such as files. To the user, a GridFS looks very much like a key-value store which supports potentially very large values. screencast 8.1 Connecting to GridFS The GridFS API is different from normal Mongo collections. Connecting works similar as with regular mongo() with one important difference: instead of specifying a collection name, we need to set a name prefix: library(mongolite) fs &lt;- gridfs(db = &quot;test&quot;, prefix = &quot;fs&quot;) Under the hood, GridFS stores files in two collections. In the case of prefix = &quot;fs&quot;: fs.chunks stores the binary chunks. fs.files stores the file metadata. Hence the prefix identifies the GridFS .chunks and .files data collections that make up the GridFS table. 8.2 GridFS Methods To get an overview of available methods, print the gridfs object. The methods are described in the ?gridfs manual page. print(fs) #&gt; &lt;gridfs&gt; #&gt; $download(name, path = &quot;.&quot;) #&gt; $drop() #&gt; $find(filter = &quot;{}&quot;, options = &quot;{}&quot;) #&gt; $read(name, con = NULL, progress = TRUE) #&gt; $remove(name) #&gt; $upload(path, name = basename(path), content_type = NULL, metadata = NULL) #&gt; $write(con, name, content_type = NULL, metadata = NULL, progress = TRUE) The basic API supports the following operations: Write (upload) new files into GridFS Read (download) files from GridFS Find (list) files in the GridFS Delete a file Note that updating (modifying) files in GridFS is currently unsupported: uploading a file with the same name will generate a new file. 8.3 Read / Write The fs$read() and fs$write() methods send data from/to an R connection, such as a file, socket or url. This is the recommended way to to send/receive data with GridFS. You get a nice progress counter and the transfer can be interrupted if needed. Both read() and write() methods have a con argument that specifies the input or output connection. You can also pass a string, which is treated as a file path. Here we stream a file from a URL: # Stream data from a URL into GridFS con &lt;- url(&#39;https://cloud.r-project.org/src/base/R-3/R-3.5.1.tar.gz&#39;) fs$write(con, &#39;source.tar.gz&#39;, progress = FALSE, metadata = &#39;{&quot;This is&quot; : &quot;just a test&quot;}&#39;) #&gt; List of 6 #&gt; $ id : chr &quot;5b636bc047a3020d733c034a&quot; #&gt; $ name : chr &quot;source.tar.gz&quot; #&gt; $ size : num 29812849 #&gt; $ date : POSIXct[1:1], format: &quot;2018-08-02 22:38:24&quot; #&gt; $ type : chr NA #&gt; $ metadata: chr &quot;{ \\&quot;This is\\&quot; : \\&quot;just a test\\&quot; }&quot; In addition, for fs$write() you can set con to a raw vector with data to upload. buf &lt;- serialize(mtcars, NULL) fs$write(buf, &quot;mtcars&quot;, progress = FALSE) #&gt; List of 6 #&gt; $ id : chr &quot;5b636bc347a3020d733c034b&quot; #&gt; $ name : chr &quot;mtcars&quot; #&gt; $ size : num 3798 #&gt; $ date : POSIXct[1:1], format: &quot;2018-08-02 22:38:27&quot; #&gt; $ type : chr NA #&gt; $ metadata: chr NA The fs$find() method shows a list of files: # List files in the GridFS fs$find() #&gt; id name size date type metadata #&gt; 1 5b636bc047a3020d733c034a source.tar.gz 29812849 2018-08-02 22:38:24 &lt;NA&gt; { &quot;This is&quot; : &quot;just a test&quot; } #&gt; 2 5b636bc347a3020d733c034b mtcars 3798 2018-08-02 22:38:27 &lt;NA&gt; &lt;NA&gt; We can read the data to disk using fs$read(): # Stream the file from GridFS to disk out &lt;- fs$read(&#39;source.tar.gz&#39;, file(&#39;source.tar.gz&#39;), progress = FALSE) file.info(&#39;source.tar.gz&#39;)$size #&gt; [1] 29812849 # Cleanup unlink(&#39;source.tar.gz&#39;) For fs$read() you can set con to NULL in which case the file will be buffered in memory and returned as a raw vector. This is useful for e.g. unserializing R objects. out &lt;- fs$read(&#39;mtcars&#39;, con = NULL, progress = FALSE) df &lt;- unserialize(out$data) head(df) #&gt; mpg cyl disp hp drat wt qsec vs am gear carb #&gt; Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 #&gt; Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 #&gt; Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 #&gt; Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 #&gt; Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 #&gt; Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 When done we trash the GridFS: fs$drop() #&gt; [1] TRUE 8.4 Vectorized Upload/Download The fs$upload() and fs$download() methods provide an alternative API specifically for transferring files between GridFS and your local disk. This API is vectorized so you can transfer many files at once. However transfers cannot be interrupted and will block R until completed. This API is only recommended to upload/download a large number of small files. # Start a new GridFS and upload all files from this book mb &lt;- mongolite::gridfs(prefix = &#39;mongobook&#39;) mb$upload(list.files(&quot;.&quot;, recursive = TRUE)) #&gt; id name size date type metadata #&gt; 1 5b636bc347a3020d733c034d _bookdown.yml 89 2018-08-02 22:38:27 &lt;NA&gt; &lt;NA&gt; #&gt; 2 5b636bc347a3020d733c034e _build.sh 80 2018-08-02 22:38:27 application/x-sh &lt;NA&gt; #&gt; 3 5b636bc347a3020d733c034f _output.yml 342 2018-08-02 22:38:27 &lt;NA&gt; &lt;NA&gt; #&gt; 4 5b636bc347a3020d733c0350 01-connecting.Rmd 9155 2018-08-02 22:38:27 text/x-markdown &lt;NA&gt; #&gt; 5 5b636bc347a3020d733c0351 02-queries.Rmd 5998 2018-08-02 22:38:27 text/x-markdown &lt;NA&gt; #&gt; 6 5b636bc347a3020d733c0352 03-insert.Rmd 3121 2018-08-02 22:38:27 text/x-markdown &lt;NA&gt; #&gt; 7 5b636bc347a3020d733c0353 04-export.Rmd 2039 2018-08-02 22:38:27 text/x-markdown &lt;NA&gt; #&gt; 8 5b636bc347a3020d733c0354 05-calculation.Rmd 2022 2018-08-02 22:38:27 text/x-markdown &lt;NA&gt; #&gt; 9 5b636bc347a3020d733c0355 06-commands.Rmd 669 2018-08-02 22:38:27 text/x-markdown &lt;NA&gt; #&gt; 10 5b636bc347a3020d733c0356 07-gridfs.Rmd 3920 2018-08-02 22:38:27 text/x-markdown &lt;NA&gt; #&gt; 11 5b636bc347a3020d733c0357 index.Rmd 3539 2018-08-02 22:38:27 text/x-markdown &lt;NA&gt; #&gt; 12 5b636bc347a3020d733c0358 fighist-1.png 47647 2018-08-02 22:38:27 image/png &lt;NA&gt; #&gt; 13 5b636bc347a3020d733c0359 figstats-1.png 52834 2018-08-02 22:38:27 image/png &lt;NA&gt; #&gt; 14 5b636bc347a3020d733c035a mongobook.Rmd 30751 2018-08-02 22:38:27 text/x-markdown &lt;NA&gt; #&gt; path #&gt; 1 /Users/jeroen/workspace/mongobook/mongobook/_bookdown.yml #&gt; 2 /Users/jeroen/workspace/mongobook/mongobook/_build.sh #&gt; 3 /Users/jeroen/workspace/mongobook/mongobook/_output.yml #&gt; 4 /Users/jeroen/workspace/mongobook/mongobook/01-connecting.Rmd #&gt; 5 /Users/jeroen/workspace/mongobook/mongobook/02-queries.Rmd #&gt; 6 /Users/jeroen/workspace/mongobook/mongobook/03-insert.Rmd #&gt; 7 /Users/jeroen/workspace/mongobook/mongobook/04-export.Rmd #&gt; 8 /Users/jeroen/workspace/mongobook/mongobook/05-calculation.Rmd #&gt; 9 /Users/jeroen/workspace/mongobook/mongobook/06-commands.Rmd #&gt; 10 /Users/jeroen/workspace/mongobook/mongobook/07-gridfs.Rmd #&gt; 11 /Users/jeroen/workspace/mongobook/mongobook/index.Rmd #&gt; 12 /Users/jeroen/workspace/mongobook/mongobook/mongobook_files/figure-html/fighist-1.png #&gt; 13 /Users/jeroen/workspace/mongobook/mongobook/mongobook_files/figure-html/figstats-1.png #&gt; 14 /Users/jeroen/workspace/mongobook/mongobook/mongobook.Rmd #&gt; [ reached getOption(&quot;max.print&quot;) -- omitted 3 rows ] In the same way we can download all files in one command: files &lt;- mb$find() dir.create(&#39;outputfiles&#39;) mb$download(files$name, &#39;outputfiles&#39;) #&gt; id name size date type metadata #&gt; 1 5b636bc347a3020d733c034d _bookdown.yml 89 2018-08-02 22:38:27 &lt;NA&gt; &lt;NA&gt; #&gt; 2 5b636bc347a3020d733c034e _build.sh 80 2018-08-02 22:38:27 application/x-sh &lt;NA&gt; #&gt; 3 5b636bc347a3020d733c034f _output.yml 342 2018-08-02 22:38:27 &lt;NA&gt; &lt;NA&gt; #&gt; 4 5b636bc347a3020d733c0350 01-connecting.Rmd 9155 2018-08-02 22:38:27 text/x-markdown &lt;NA&gt; #&gt; 5 5b636bc347a3020d733c0351 02-queries.Rmd 5998 2018-08-02 22:38:27 text/x-markdown &lt;NA&gt; #&gt; 6 5b636bc347a3020d733c0352 03-insert.Rmd 3121 2018-08-02 22:38:27 text/x-markdown &lt;NA&gt; #&gt; 7 5b636bc347a3020d733c0353 04-export.Rmd 2039 2018-08-02 22:38:27 text/x-markdown &lt;NA&gt; #&gt; 8 5b636bc347a3020d733c0354 05-calculation.Rmd 2022 2018-08-02 22:38:27 text/x-markdown &lt;NA&gt; #&gt; 9 5b636bc347a3020d733c0355 06-commands.Rmd 669 2018-08-02 22:38:27 text/x-markdown &lt;NA&gt; #&gt; 10 5b636bc347a3020d733c0356 07-gridfs.Rmd 3920 2018-08-02 22:38:27 text/x-markdown &lt;NA&gt; #&gt; 11 5b636bc347a3020d733c0357 index.Rmd 3539 2018-08-02 22:38:27 text/x-markdown &lt;NA&gt; #&gt; 12 5b636bc347a3020d733c0358 fighist-1.png 47647 2018-08-02 22:38:27 image/png &lt;NA&gt; #&gt; 13 5b636bc347a3020d733c0359 figstats-1.png 52834 2018-08-02 22:38:27 image/png &lt;NA&gt; #&gt; 14 5b636bc347a3020d733c035a mongobook.Rmd 30751 2018-08-02 22:38:27 text/x-markdown &lt;NA&gt; #&gt; path #&gt; 1 outputfiles/_bookdown.yml #&gt; 2 outputfiles/_build.sh #&gt; 3 outputfiles/_output.yml #&gt; 4 outputfiles/01-connecting.Rmd #&gt; 5 outputfiles/02-queries.Rmd #&gt; 6 outputfiles/03-insert.Rmd #&gt; 7 outputfiles/04-export.Rmd #&gt; 8 outputfiles/05-calculation.Rmd #&gt; 9 outputfiles/06-commands.Rmd #&gt; 10 outputfiles/07-gridfs.Rmd #&gt; 11 outputfiles/index.Rmd #&gt; 12 outputfiles/fighist-1.png #&gt; 13 outputfiles/figstats-1.png #&gt; 14 outputfiles/mongobook.Rmd #&gt; [ reached getOption(&quot;max.print&quot;) -- omitted 3 rows ] list.files(&#39;outputfiles&#39;) #&gt; [1] &quot;_bookdown.yml&quot; &quot;_build.sh&quot; &quot;_output.yml&quot; &quot;01-connecting.Rmd&quot; &quot;02-queries.Rmd&quot; #&gt; [6] &quot;03-insert.Rmd&quot; &quot;04-export.Rmd&quot; &quot;05-calculation.Rmd&quot; &quot;06-commands.Rmd&quot; &quot;07-gridfs.Rmd&quot; #&gt; [11] &quot;fighist-1.png&quot; &quot;figstats-1.png&quot; &quot;index.Rmd&quot; &quot;mongobook.Rmd&quot; &quot;mongobook.Rproj&quot; #&gt; [16] &quot;style.css&quot; &quot;toc.css&quot; This makes a convenient way to store an large set of files into GridFS. # All done unlink(&#39;outputfiles&#39;, recursive = TRUE) mb$drop() #&gt; [1] TRUE "]
]
